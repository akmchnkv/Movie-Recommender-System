{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-12-03T14:51:01.468195Z",
     "iopub.status.busy": "2023-12-03T14:51:01.467932Z",
     "iopub.status.idle": "2023-12-03T14:51:03.397991Z",
     "shell.execute_reply": "2023-12-03T14:51:03.396748Z",
     "shell.execute_reply.started": "2023-12-03T14:51:01.468170Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-12-03T14:51:03.400371Z",
     "iopub.status.busy": "2023-12-03T14:51:03.399918Z",
     "iopub.status.idle": "2023-12-03T14:51:03.494279Z",
     "shell.execute_reply": "2023-12-03T14:51:03.493294Z",
     "shell.execute_reply.started": "2023-12-03T14:51:03.400340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0      196       242       3\n",
       "1      186       302       3\n",
       "2       22       377       1\n",
       "3      244        51       2\n",
       "4      166       346       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rating_df = pd.read_csv('../data/interim/rating_df.csv')\n",
    "rating_df = pd.read_csv('/kaggle/input/movielens/rating_df.csv')\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-12-03T14:51:03.495651Z",
     "iopub.status.busy": "2023-12-03T14:51:03.495363Z",
     "iopub.status.idle": "2023-12-03T14:51:03.577786Z",
     "shell.execute_reply": "2023-12-03T14:51:03.577015Z",
     "shell.execute_reply.started": "2023-12-03T14:51:03.495625Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(rating_df, test_size=0.2, \n",
    "                                    stratify=rating_df['user_id'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-12-03T14:51:03.581127Z",
     "iopub.status.busy": "2023-12-03T14:51:03.580331Z",
     "iopub.status.idle": "2023-12-03T14:51:03.585768Z",
     "shell.execute_reply": "2023-12-03T14:51:03.584974Z",
     "shell.execute_reply.started": "2023-12-03T14:51:03.581089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 3) (20000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-12-03T14:51:03.587332Z",
     "iopub.status.busy": "2023-12-03T14:51:03.586983Z",
     "iopub.status.idle": "2023-12-03T14:51:09.496177Z",
     "shell.execute_reply": "2023-12-03T14:51:09.495355Z",
     "shell.execute_reply.started": "2023-12-03T14:51:03.587302Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user_id, item_id, rating = self.df.iloc[idx]\n",
    "        sample = {\"user\": user_id - 1, \"item\": item_id - 1, \"rating\": rating}\n",
    "        return sample\n",
    "    \n",
    "train_loader = DataLoader(MovieDataset(train_df), batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(MovieDataset(val_df), batch_size=16, shuffle=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Matrix Factorization Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Reference: https://towardsdatascience.com/recommendation-system-matrix-factorization-d61978660b4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-12-03T14:51:09.498940Z",
     "iopub.status.busy": "2023-12-03T14:51:09.498521Z",
     "iopub.status.idle": "2023-12-03T14:51:09.550729Z",
     "shell.execute_reply": "2023-12-03T14:51:09.549996Z",
     "shell.execute_reply.started": "2023-12-03T14:51:09.498912Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=20):\n",
    "        super(MatrixFactorization, self).__init__()\n",
    "        self.user_embeddings = nn.Embedding(num_users, embedding_dim, sparse=True)\n",
    "        self.item_embeddings = nn.Embedding(num_items, embedding_dim, sparse=True)\n",
    "\n",
    "    def forward(self, user_input, item_input):\n",
    "        user_emb = self.user_embeddings(user_input)\n",
    "        item_emb = self.item_embeddings(item_input)\n",
    "        return torch.sum(user_emb * item_emb, dim=1)\n",
    "    \n",
    "num_user = 943\n",
    "num_item = 1682\n",
    "\n",
    "model = MatrixFactorization(num_user, num_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-12-03T14:51:09.552170Z",
     "iopub.status.busy": "2023-12-03T14:51:09.551881Z",
     "iopub.status.idle": "2023-12-03T14:51:09.563963Z",
     "shell.execute_reply": "2023-12-03T14:51:09.563100Z",
     "shell.execute_reply.started": "2023-12-03T14:51:09.552145Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, device, num_epochs, train_loader, valid_loader, loss_fn, optimizer):\n",
    "    model.to(device)\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        with tqdm(\n",
    "            total=len(train_df), desc=f\"Epoch {epoch}/{num_epochs}\", unit=\"items\"\n",
    "        ) as pbar:\n",
    "            for batch in train_loader:\n",
    "                user = batch['user']\n",
    "                item = batch['item']\n",
    "                rating = batch['rating']\n",
    "                \n",
    "                user, item, rating = user.to(device), item.to(device), rating.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(user, item)\n",
    "                loss = loss_fn(outputs, rating.float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                pbar.update(user.shape[0])\n",
    "                pbar.set_postfix(**{\"loss (batch)\": loss.item()})\n",
    "                \n",
    "        model.eval()\n",
    "        \n",
    "        with tqdm(total=len(val_df), desc=f\"Validation\", unit=\"items\") as pbar:\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    user = batch['user']\n",
    "                    item = batch['item']\n",
    "                    rating = batch['rating']\n",
    "                    user, item, rating = user.to(device), item.to(device), rating.to(device)\n",
    "\n",
    "                    outputs = model(user, item)\n",
    "                    loss = loss_fn(outputs, rating)\n",
    "            \n",
    "                    pbar.update(user.shape[0])\n",
    "                    epoch_loss += loss.item()\n",
    "                    pbar.set_postfix(**{\"loss (batch)\": loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-12-03T14:51:09.565262Z",
     "iopub.status.busy": "2023-12-03T14:51:09.565002Z",
     "iopub.status.idle": "2023-12-03T14:59:55.312391Z",
     "shell.execute_reply": "2023-12-03T14:59:55.311385Z",
     "shell.execute_reply.started": "2023-12-03T14:51:09.565239Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 80000/80000 [00:15<00:00, 5321.33items/s, loss (batch)=30.6]\n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 6891.18items/s, loss (batch)=18]  \n",
      "Epoch 2/30: 100%|██████████| 80000/80000 [00:14<00:00, 5525.66items/s, loss (batch)=22.1]\n",
      "Validation: 100%|██████████| 20000/20000 [00:03<00:00, 6511.16items/s, loss (batch)=15.9]\n",
      "Epoch 3/30: 100%|██████████| 80000/80000 [00:14<00:00, 5466.38items/s, loss (batch)=14.2]\n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 6881.42items/s, loss (batch)=14.2]\n",
      "Epoch 4/30: 100%|██████████| 80000/80000 [00:14<00:00, 5405.47items/s, loss (batch)=16]  \n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 6820.36items/s, loss (batch)=12.1]\n",
      "Epoch 5/30: 100%|██████████| 80000/80000 [00:14<00:00, 5444.51items/s, loss (batch)=4.07]\n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 6769.60items/s, loss (batch)=10.1]\n",
      "Epoch 6/30: 100%|██████████| 80000/80000 [00:14<00:00, 5424.25items/s, loss (batch)=6.49]\n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 6860.72items/s, loss (batch)=8.6] \n",
      "Epoch 7/30: 100%|██████████| 80000/80000 [00:14<00:00, 5541.86items/s, loss (batch)=3.86] \n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 6913.06items/s, loss (batch)=7.52]\n",
      "Epoch 8/30: 100%|██████████| 80000/80000 [00:14<00:00, 5440.84items/s, loss (batch)=6.04] \n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 6973.50items/s, loss (batch)=6.64]\n",
      "Epoch 9/30: 100%|██████████| 80000/80000 [00:14<00:00, 5534.39items/s, loss (batch)=3.08] \n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 7014.63items/s, loss (batch)=5.91] \n",
      "Epoch 10/30: 100%|██████████| 80000/80000 [00:14<00:00, 5515.97items/s, loss (batch)=1.83] \n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 6800.64items/s, loss (batch)=5.29]\n",
      "Epoch 11/30: 100%|██████████| 80000/80000 [00:14<00:00, 5580.43items/s, loss (batch)=6.08] \n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 6744.16items/s, loss (batch)=4.77] \n",
      "Epoch 12/30: 100%|██████████| 80000/80000 [00:14<00:00, 5557.00items/s, loss (batch)=0.735]\n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 7014.57items/s, loss (batch)=4.37] \n",
      "Epoch 13/30: 100%|██████████| 80000/80000 [00:14<00:00, 5517.51items/s, loss (batch)=2.84] \n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 6883.92items/s, loss (batch)=4.08] \n",
      "Epoch 14/30: 100%|██████████| 80000/80000 [00:14<00:00, 5575.36items/s, loss (batch)=1.11] \n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 6897.08items/s, loss (batch)=3.81] \n",
      "Epoch 15/30: 100%|██████████| 80000/80000 [00:14<00:00, 5442.15items/s, loss (batch)=1.93] \n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 7045.82items/s, loss (batch)=3.58] \n",
      "Epoch 16/30: 100%|██████████| 80000/80000 [00:14<00:00, 5519.09items/s, loss (batch)=1.49] \n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 6857.45items/s, loss (batch)=3.41] \n",
      "Epoch 17/30: 100%|██████████| 80000/80000 [00:14<00:00, 5491.78items/s, loss (batch)=2.93] \n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 6979.29items/s, loss (batch)=3.26] \n",
      "Epoch 18/30: 100%|██████████| 80000/80000 [00:14<00:00, 5593.29items/s, loss (batch)=0.852]\n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 7021.05items/s, loss (batch)=3.1]  \n",
      "Epoch 19/30: 100%|██████████| 80000/80000 [00:14<00:00, 5583.74items/s, loss (batch)=2.23] \n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 7065.94items/s, loss (batch)=2.98] \n",
      "Epoch 20/30: 100%|██████████| 80000/80000 [00:14<00:00, 5594.66items/s, loss (batch)=0.541]\n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 6909.44items/s, loss (batch)=2.88] \n",
      "Epoch 21/30: 100%|██████████| 80000/80000 [00:14<00:00, 5632.27items/s, loss (batch)=1]    \n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 6844.99items/s, loss (batch)=2.79] \n",
      "Epoch 22/30: 100%|██████████| 80000/80000 [00:14<00:00, 5584.28items/s, loss (batch)=1.04] \n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 6911.76items/s, loss (batch)=2.76] \n",
      "Epoch 23/30: 100%|██████████| 80000/80000 [00:14<00:00, 5533.05items/s, loss (batch)=1.15] \n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 7044.80items/s, loss (batch)=2.67] \n",
      "Epoch 24/30: 100%|██████████| 80000/80000 [00:14<00:00, 5555.96items/s, loss (batch)=2.4]  \n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 7002.44items/s, loss (batch)=2.61] \n",
      "Epoch 25/30: 100%|██████████| 80000/80000 [00:14<00:00, 5634.18items/s, loss (batch)=1.33] \n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 7030.50items/s, loss (batch)=2.59] \n",
      "Epoch 26/30: 100%|██████████| 80000/80000 [00:14<00:00, 5586.72items/s, loss (batch)=0.85] \n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 7024.27items/s, loss (batch)=2.54] \n",
      "Epoch 27/30: 100%|██████████| 80000/80000 [00:14<00:00, 5574.87items/s, loss (batch)=1.18] \n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 7043.96items/s, loss (batch)=2.49] \n",
      "Epoch 28/30: 100%|██████████| 80000/80000 [00:14<00:00, 5559.72items/s, loss (batch)=0.492]\n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 6922.98items/s, loss (batch)=2.46] \n",
      "Epoch 29/30: 100%|██████████| 80000/80000 [00:14<00:00, 5619.95items/s, loss (batch)=0.961]\n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 7173.30items/s, loss (batch)=2.42] \n",
      "Epoch 30/30: 100%|██████████| 80000/80000 [00:14<00:00, 5499.01items/s, loss (batch)=1.09] \n",
      "Validation: 100%|██████████| 20000/20000 [00:02<00:00, 6904.85items/s, loss (batch)=2.38] \n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "num_epoch = 30\n",
    "train(model, device, num_epoch, train_loader, val_loader, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-12-03T14:59:55.314506Z",
     "iopub.status.busy": "2023-12-03T14:59:55.313829Z",
     "iopub.status.idle": "2023-12-03T14:59:55.344222Z",
     "shell.execute_reply": "2023-12-03T14:59:55.343291Z",
     "shell.execute_reply.started": "2023-12-03T14:59:55.314469Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"matrix_factorixation.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-12-03T14:59:55.348325Z",
     "iopub.status.busy": "2023-12-03T14:59:55.348019Z",
     "iopub.status.idle": "2023-12-03T14:59:55.357941Z",
     "shell.execute_reply": "2023-12-03T14:59:55.357172Z",
     "shell.execute_reply.started": "2023-12-03T14:59:55.348299Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = MatrixFactorization(num_user, num_item)\n",
    "# model.load_state_dict(torch.load('/kaggle/working/matrix_factorixation.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-12-03T14:59:55.359197Z",
     "iopub.status.busy": "2023-12-03T14:59:55.358945Z",
     "iopub.status.idle": "2023-12-03T14:59:55.438817Z",
     "shell.execute_reply": "2023-12-03T14:59:55.437873Z",
     "shell.execute_reply.started": "2023-12-03T14:59:55.359174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>unknown</th>\n",
       "      <th>action</th>\n",
       "      <th>adventure</th>\n",
       "      <th>animation</th>\n",
       "      <th>childrens</th>\n",
       "      <th>comedy</th>\n",
       "      <th>crime</th>\n",
       "      <th>...</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>film_noir</th>\n",
       "      <th>horror</th>\n",
       "      <th>musical</th>\n",
       "      <th>mystery</th>\n",
       "      <th>romance</th>\n",
       "      <th>sci_fi</th>\n",
       "      <th>thriller</th>\n",
       "      <th>war</th>\n",
       "      <th>western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id        movie_title release_date  unknown  action  adventure  \\\n",
       "0         1   Toy Story (1995)  01-Jan-1995        0       0          0   \n",
       "1         2   GoldenEye (1995)  01-Jan-1995        0       1          1   \n",
       "2         3  Four Rooms (1995)  01-Jan-1995        0       0          0   \n",
       "3         4  Get Shorty (1995)  01-Jan-1995        0       1          0   \n",
       "4         5     Copycat (1995)  01-Jan-1995        0       0          0   \n",
       "\n",
       "   animation  childrens  comedy  crime  ...  fantasy  film_noir  horror  \\\n",
       "0          1          1       1      0  ...        0          0       0   \n",
       "1          0          0       0      0  ...        0          0       0   \n",
       "2          0          0       0      0  ...        0          0       0   \n",
       "3          0          0       1      0  ...        0          0       0   \n",
       "4          0          0       0      1  ...        0          0       0   \n",
       "\n",
       "   musical  mystery  romance  sci_fi  thriller  war  western  \n",
       "0        0        0        0       0         0    0        0  \n",
       "1        0        0        0       0         1    0        0  \n",
       "2        0        0        0       0         1    0        0  \n",
       "3        0        0        0       0         0    0        0  \n",
       "4        0        0        0       0         1    0        0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_df = pd.read_csv('/kaggle/input/itemsmovie/item_df.csv')\n",
    "# item_df = pd.read_csv('../data/interim/item_df.csv')\n",
    "item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-12-03T14:59:55.440191Z",
     "iopub.status.busy": "2023-12-03T14:59:55.439912Z",
     "iopub.status.idle": "2023-12-03T14:59:55.479827Z",
     "shell.execute_reply": "2023-12-03T14:59:55.478893Z",
     "shell.execute_reply.started": "2023-12-03T14:59:55.440166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype\n",
      "---  ------    --------------   -----\n",
      " 0   user_id   100000 non-null  int64\n",
      " 1   movie_id  100000 non-null  int64\n",
      " 2   rating    100000 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 2.3 MB\n"
     ]
    }
   ],
   "source": [
    "rating_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-12-03T14:59:55.481374Z",
     "iopub.status.busy": "2023-12-03T14:59:55.481101Z",
     "iopub.status.idle": "2023-12-03T14:59:55.495314Z",
     "shell.execute_reply": "2023-12-03T14:59:55.494406Z",
     "shell.execute_reply.started": "2023-12-03T14:59:55.481349Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def predict_rating(rec_df, rating_df):\n",
    "    model.eval()\n",
    "    dataloader = DataLoader(MovieDataset(rec_df), batch_size=16, shuffle=False,)\n",
    "    pbar = tqdm(dataloader, total=len(dataloader))\n",
    "    preds = []\n",
    "    for data in pbar:\n",
    "        user = data['user']\n",
    "        item = data['item']\n",
    "        rating = data['rating']\n",
    "        user, item, rating = user.to(device), item.to(device), rating.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds.append(model(user, item))\n",
    "\n",
    "    preds = torch.cat(preds).cpu().detach().numpy()\n",
    "    movie_ids = rec_df['movie_id'].unique()\n",
    "    \n",
    "    # Calculate average ratings for movies in rec_df\n",
    "    avg_ratings = rating_df[rating_df['movie_id'].isin(movie_ids)].groupby('movie_id')['rating'].mean()\n",
    "    scaler = MinMaxScaler(feature_range=(1, 5)) # Scale average ratings to range (1, 5)\n",
    "    avg_ratings = scaler.fit_transform(avg_ratings.values.reshape(-1, 1))\n",
    "    avg_ratings = avg_ratings.flatten()\n",
    "\n",
    "    rec_df['rating'] = rec_df['movie_id'].map(dict(zip(movie_ids, avg_ratings))).fillna(0)\n",
    "    return rec_df, preds\n",
    "\n",
    "\n",
    "def recommend_for_user(user_id, rating_df, item_df, top_n=10):\n",
    "    rec_df = rating_df.query(\"user_id != @user_id\")\n",
    "    rec_df['user_id'] = user_id\n",
    "    rec_df = rec_df.drop_duplicates(subset=['user_id', 'movie_id'])\n",
    "\n",
    "    rec_df, preds = predict_rating(rec_df, rating_df)\n",
    "\n",
    "    d = dict(zip(item_df.movie_id, item_df.movie_title))\n",
    "    rec_df['title'] = rec_df['movie_id'].map(d)\n",
    "    rec_df['rating'] = preds\n",
    "    rec_df['rating'] = preds.clip(1, 5)\n",
    "    rec_df = rec_df.sort_values('rating', ascending=False)\n",
    "\n",
    "    #  Print top_n recommended movies with their ratings\n",
    "    print('\\nRECOMMENDATIONS')\n",
    "    print(rec_df[['title','rating']].head(top_n))\n",
    "\n",
    "    user_df = rating_df.query(\"user_id == @user_id\")\n",
    "    user_df['title'] = user_df['movie_id'].map(d)\n",
    "    user_df = user_df.sort_values('rating', ascending=False)\n",
    "\n",
    "    # Print top_n movies already watched by the user with their ratings\n",
    "    print('\\nWHAT ALREADY WATCHED')\n",
    "    print(user_df[['title','rating']].head(top_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-12-03T14:59:55.497019Z",
     "iopub.status.busy": "2023-12-03T14:59:55.496598Z",
     "iopub.status.idle": "2023-12-03T14:59:55.729540Z",
     "shell.execute_reply": "2023-12-03T14:59:55.728594Z",
     "shell.execute_reply.started": "2023-12-03T14:59:55.496983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:00<00:00, 846.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RECOMMENDATIONS\n",
      "                                                   title  rating\n",
      "24592                                   Show, The (1995)     5.0\n",
      "7288                                Nobody's Fool (1994)     5.0\n",
      "5291                                   Out to Sea (1997)     5.0\n",
      "1282                            Gay Divorcee, The (1934)     5.0\n",
      "7341                                Mrs. Dalloway (1997)     5.0\n",
      "4320   Nosferatu (Nosferatu, eine Symphonie des Graue...     5.0\n",
      "424               American Werewolf in London, An (1981)     5.0\n",
      "1498                               Paths of Glory (1957)     5.0\n",
      "426                         Home for the Holidays (1995)     5.0\n",
      "451                            Three Colors: Blue (1993)     5.0\n",
      "\n",
      "WHAT ALREADY WATCHED\n",
      "                                           title  rating\n",
      "99373                           Toy Story (1995)       5\n",
      "23123                        My Fair Lady (1964)       5\n",
      "72668                 Singin' in the Rain (1952)       5\n",
      "63569                        12 Angry Men (1957)       5\n",
      "16952                      Quiet Man, The (1952)       5\n",
      "17888                      On Golden Pond (1981)       5\n",
      "18625                     Golden Earrings (1947)       5\n",
      "19569                      Mrs. Doubtfire (1993)       5\n",
      "56469                    Deer Hunter, The (1978)       5\n",
      "21593  Butch Cassidy and the Sundance Kid (1969)       5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "user_id = random.choice(rating_df.user_id.values)\n",
    "print(user_id)\n",
    "\n",
    "recommend_for_user(user_id, rating_df, item_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-12-03T14:59:55.731677Z",
     "iopub.status.busy": "2023-12-03T14:59:55.731267Z",
     "iopub.status.idle": "2023-12-03T15:01:50.530643Z",
     "shell.execute_reply": "2023-12-03T15:01:50.529665Z",
     "shell.execute_reply.started": "2023-12-03T14:59:55.731642Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Users: 100%|██████████| 943/943 [01:54<00:00,  8.22user/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE: 1.35172\n",
      "Precision: 0.5308557205390095\n",
      "Recall: 0.29173152209801423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def predict_rating_for_user(model, user_id, watched_movies, target_movie_id, device):\n",
    "    model.eval()\n",
    "    user_input = torch.tensor([user_id - 1], dtype=torch.long).to(device)\n",
    "    watched_movie_input = torch.tensor([movie_id - 1 for movie_id in watched_movies], dtype=torch.long).to(device)\n",
    "    target_movie_input = torch.tensor([target_movie_id - 1], dtype=torch.long).to(device)\n",
    "\n",
    "    # Extract embeddings for the user and movies\n",
    "    user_embedding = model.user_embeddings(user_input)\n",
    "    watched_movie_embeddings = model.item_embeddings(watched_movie_input)\n",
    "    target_movie_embedding = model.item_embeddings(target_movie_input)\n",
    "\n",
    "    # Compute the dot product of user and target movie embeddings\n",
    "    prediction = torch.sum(user_embedding * target_movie_embedding)\n",
    "\n",
    "    return prediction.item()\n",
    "\n",
    "\n",
    "true_positives = 0\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "\n",
    "unique_user_ids = rating_df['user_id'].unique()\n",
    "mse_scores = []\n",
    "\n",
    "for user_id in tqdm(unique_user_ids, desc=\"Users\", unit=\"user\"):\n",
    "    user_df = rating_df[rating_df['user_id'] == user_id].copy()\n",
    "\n",
    "    for index, row in user_df.iterrows():\n",
    "        movie_id = row['movie_id']\n",
    "        user_df_excluded = user_df[user_df['movie_id'] != movie_id]\n",
    "\n",
    "        pred_rating = round(predict_rating_for_user(model, user_id, np.array(user_df_excluded['movie_id']), movie_id, device))\n",
    "        true_rating = row['rating']\n",
    "\n",
    "        mse = mean_squared_error([true_rating], [pred_rating])\n",
    "        mse_scores.append(mse)\n",
    "\n",
    "        threshold = 4.5  \n",
    "        if round(pred_rating) >= threshold and true_rating >= threshold:\n",
    "            true_positives += 1\n",
    "        elif round(pred_rating) >= threshold and true_rating < threshold:\n",
    "            false_positives += 1\n",
    "        elif round(pred_rating) < threshold and true_rating >= threshold:\n",
    "            false_negatives += 1\n",
    "\n",
    "average_mse = np.mean(mse_scores)\n",
    "print(f\"Average MSE: {average_mse}\")\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4082843,
     "sourceId": 7086273,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4083303,
     "sourceId": 7086975,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4098188,
     "sourceId": 7108153,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
